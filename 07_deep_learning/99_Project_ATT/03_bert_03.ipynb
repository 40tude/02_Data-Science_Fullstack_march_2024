{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\phili\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.models.bert.modeling_tf_bert because of the following error (look up to see its traceback):\nDLL load failed while importing _errors: La procédure spécifiée est introuvable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\phili\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\transformers\\utils\\import_utils.py:1172\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1171\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1172\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1173\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\phili\\anaconda3\\envs\\tf_cpu\\lib\\importlib\\__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:986\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:680\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:850\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:228\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\phili\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py:38\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_tf_outputs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     28\u001b[0m     TFBaseModelOutputWithPastAndCrossAttentions,\n\u001b[0;32m     29\u001b[0m     TFBaseModelOutputWithPoolingAndCrossAttentions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     36\u001b[0m     TFTokenClassifierOutput,\n\u001b[0;32m     37\u001b[0m )\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_tf_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     39\u001b[0m     TFCausalLanguageModelingLoss,\n\u001b[0;32m     40\u001b[0m     TFMaskedLanguageModelingLoss,\n\u001b[0;32m     41\u001b[0m     TFModelInputType,\n\u001b[0;32m     42\u001b[0m     TFMultipleChoiceLoss,\n\u001b[0;32m     43\u001b[0m     TFNextSentencePredictionLoss,\n\u001b[0;32m     44\u001b[0m     TFPreTrainedModel,\n\u001b[0;32m     45\u001b[0m     TFQuestionAnsweringLoss,\n\u001b[0;32m     46\u001b[0m     TFSequenceClassificationLoss,\n\u001b[0;32m     47\u001b[0m     TFTokenClassificationLoss,\n\u001b[0;32m     48\u001b[0m     get_initializer,\n\u001b[0;32m     49\u001b[0m     keras_serializable,\n\u001b[0;32m     50\u001b[0m     unpack_inputs,\n\u001b[0;32m     51\u001b[0m )\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m shape_list, stable_softmax\n",
      "File \u001b[1;32mc:\\Users\\phili\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\transformers\\modeling_tf_utils.py:30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING, Any, Callable, Dict, List, Optional, Union\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mh5py\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\phili\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\h5py\\__init__.py:25\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _errors\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _errors: La procédure spécifiée est introuvable.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 33\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ReduceLROnPlateau\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TensorBoard\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TFBertForSequenceClassification, BertTokenizer \u001b[38;5;66;03m# 'TF' for TensorFlow models\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# , trainer, TrainingArguments           \u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1055\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\phili\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\transformers\\utils\\import_utils.py:1163\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1161\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   1162\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[1;32m-> 1163\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1165\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\phili\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\transformers\\utils\\import_utils.py:1162\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1160\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(name)\n\u001b[0;32m   1161\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m-> 1162\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1163\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m   1164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\phili\\anaconda3\\envs\\tf_cpu\\lib\\site-packages\\transformers\\utils\\import_utils.py:1174\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1172\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   1173\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1174\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1175\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1176\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1177\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to import transformers.models.bert.modeling_tf_bert because of the following error (look up to see its traceback):\nDLL load failed while importing _errors: La procédure spécifiée est introuvable."
     ]
    }
   ],
   "source": [
    "\n",
    "# !Z conda activate tf_cpu\n",
    "# This code use \n",
    "#   BertForSequenceClassification\n",
    "#   bert-base-uncased (where cat & CAT are the same)\n",
    "\n",
    "\n",
    "# conda create --name tf_cpu python=3.9\n",
    "# conda activate tf_cpu\n",
    "# pip install tensorflow (=> 2.17.0)y\n",
    "# conda install tf-keras (=> 2.15)\n",
    "# conda install transformers (=> 4.44)\n",
    "\n",
    "# conda install transformers (=> 4.44 + keras 3.5 qui n'est pas supporté)\n",
    "#       Failed to import transformers.models.bert.modeling_tf_bert because of the following error (look up to see its traceback):\n",
    "#       Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.\n",
    "# pip uninstall keras\n",
    "\n",
    "## pip install transformers==4.29.0\n",
    "## pip install tokenizers==0.13.3\n",
    "\n",
    "# prelude\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "# import numpy as np\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "\n",
    "from transformers import TFBertForSequenceClassification, BertTokenizer # 'TF' for TensorFlow models\n",
    "# , trainer, TrainingArguments           \n",
    "from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pathlib import Path\n",
    "k_Current_dir = Path.cwd()\n",
    "k_AssetsDir = \"assets\"\n",
    "k_sms_max_len = 100\n",
    "k_random_state  = 42\n",
    "k_test_size     = 0.3\n",
    "\n",
    "\n",
    "# Regarding the warning : TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html from .autonotebook import tqdm as notebook_tqdm\n",
    "# Solution ? \n",
    "# ! NOT TESTED YET - Does it apply to Jupyter \"in\" VSCode ?\n",
    "# https://saturncloud.io/blog/importerror-iprogress-not-found-please-update-jupyter-and-ipywidgets-although-it-is-installed/\n",
    "# conda install -c conda-forge ipywidgets\n",
    "# jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# drop empty cols and duplicates, rename cols...\n",
    "def cleaner(df):\n",
    "    df.drop(columns=\"Unnamed: 2\", inplace=True)\n",
    "    df.drop(columns=\"Unnamed: 3\", inplace=True)\n",
    "    df.drop(columns=\"Unnamed: 4\", inplace=True)\n",
    "\n",
    "    df.drop_duplicates(inplace=True)\n",
    "\n",
    "    df.columns = df.columns.str.lower()\n",
    "    df.columns = df.columns.str.replace(\"/\", \"_\")\n",
    "\n",
    "    df.rename(columns={\"v1\": \"label\"}, inplace=True)\n",
    "    df.rename(columns={\"v2\": \"sms\"}, inplace=True)\n",
    "\n",
    "    df[\"label\"] = df[\"label\"].map({\"ham\": 0, \"spam\": 1})\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = Path(f\"{k_Current_dir/k_AssetsDir/fig_id}.{fig_extension}\")\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(k_Current_dir / k_AssetsDir / \"spam.csv\", encoding=\"cp1252\")\n",
    "df = cleaner(df)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['sms'], df['label'], test_size=k_test_size, random_state=k_random_state, stratify=df['label'])\n",
    "\n",
    "model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)  # modèle TensorFlow\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# On ne peut pas utiliser la classe trainer de Pytorch\n",
    "# Il faut utiliser les outils TensorFlow\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',           # can be 'val_accuracy' if needed \n",
    "    patience=3,          \n",
    "    restore_best_weights=True  \n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=0.2,       # reduction factor of learning rate\n",
    "    patience=2,       \n",
    "    min_lr=1e-7       # minimal value for learning rate\n",
    ")\n",
    "\n",
    "path = Path(f\"{k_Current_dir/k_AssetsDir/'bert_base_uncased_best_model.h5'}\")\n",
    "checkpoint = ModelCheckpoint(\n",
    "    path,                       # model's path\n",
    "    monitor='val_loss', \n",
    "    save_best_only=True, \n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='logs', histogram_freq=1)\n",
    "print(f\"\\n\\n--------------------------------------------------\")\n",
    "print(f\"Once the model runs, open a terminal, make sure you are in the directory of the project and type in : \")\n",
    "print(f\"tensorboard --logdir=logs\")\n",
    "print(f\"Then visit the URL\")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=3e-5), \n",
    "    loss='binary_crossentropy', \n",
    "    metrics=[tf.keras.metrics.Recall(name=\"recall\"), tf.keras.metrics.Precision(name=\"precision\"), \"accuracy\"],       # name=... avoid recall_1 for example\n",
    ")\n",
    "\n",
    "# Tokenisation des textes pour l'entrée du modèle\n",
    "train_encodings = tokenizer(\n",
    "    X_train.tolist(),\n",
    "    truncation=True,           # tronque si le texte est trop long pour BERT\n",
    "    padding=True,              # ajoute du padding pour aligner les longueurs des séquences\n",
    "    max_length=128,            # longueur max des séquences\n",
    "    return_tensors='tf'        # retourne des tenseurs TensorFlow\n",
    ")\n",
    "\n",
    "test_encodings = tokenizer(\n",
    "    X_test.tolist(),\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    max_length=128,\n",
    "    return_tensors='tf'\n",
    ")\n",
    "\n",
    "# Conversion des labels en tenseurs TensorFlow\n",
    "y_train_tf = tf.convert_to_tensor(y_train.tolist())\n",
    "y_test_tf = tf.convert_to_tensor(y_test.tolist())\n",
    "\n",
    "# Entraînement du modèle\n",
    "history = model.fit(\n",
    "    x={\"input_ids\": train_encodings['input_ids'], \"attention_mask\": train_encodings['attention_mask']},   # entrée des tokens et des masques\n",
    "    y=y_train_tf,                          # les labels\n",
    "    validation_data=(\n",
    "        {\"input_ids\": test_encodings['input_ids'], \"attention_mask\": test_encodings['attention_mask']},  # entrée de validation\n",
    "        y_test_tf                           # labels de validation\n",
    "    ),\n",
    "    batch_size=32,\n",
    "    epochs=50,\n",
    "    callbacks=[early_stopping, reduce_lr, checkpoint, tensorboard]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(f\"{k_Current_dir/k_AssetsDir/'bert_base_uncased_arch.png'}\")\n",
    "tf.keras.utils.plot_model(model, path, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"], color=\"b\", label=\"Train Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], color=\"r\", label=\"Val Loss\")\n",
    "plt.ylabel(\"Values\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.title(\"Bert Base Uncased : Loss\")\n",
    "plt.legend()\n",
    "plt.ylim(0,1)\n",
    "save_fig(\"bert_base_uncased_loss\", \"png\")\n",
    "plt.show()\n",
    "\n",
    "display([[round(f, 6) for f in history.history['loss'][-10:]]])\n",
    "display([[round(f, 6) for f in history.history['val_loss'][-10:]]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"accuracy\"], color=\"b\", label=\"Train Accuracy\")\n",
    "plt.plot(history.history[\"val_accuracy\"], color=\"r\", label=\"Val Accuracy\")\n",
    "plt.ylabel(\"Values\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.title(\"Bert Base Uncased : Accuracy\")\n",
    "plt.legend()\n",
    "plt.ylim(0,1)\n",
    "save_fig(\"bert_base_uncased_accuracy\", \"png\")\n",
    "plt.show()\n",
    "\n",
    "display([[round(f, 6) for f in history.history['accuracy'][-10:]]])\n",
    "display([[round(f, 6) for f in history.history['val_accuracy'][-10:]]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"precision\"], color=\"b\", label=\"Train Precision\")\n",
    "plt.plot(history.history[\"val_precision\"], color=\"r\", label=\"Val Precision\")\n",
    "plt.ylabel(\"Values\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.title(\"Bert Base Uncased : Precision\")\n",
    "plt.legend()\n",
    "plt.ylim(0,1)\n",
    "save_fig(\"bert_base_uncased_precision\", \"png\")\n",
    "plt.show()\n",
    "\n",
    "display([[round(f, 6) for f in history.history['precision'][-10:]]])\n",
    "display([[round(f, 6) for f in history.history['val_precision'][-10:]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"recall\"], color=\"b\", label=\"Train Recall\")\n",
    "plt.plot(history.history[\"val_recall\"], color=\"r\", label=\"Val Recall\")\n",
    "plt.ylabel(\"Values\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.title(\"Bert Base Uncased : Recall\")\n",
    "plt.legend()\n",
    "plt.ylim(0,1)\n",
    "save_fig(\"bert_base_uncased_recall\", \"png\")\n",
    "plt.show()\n",
    "\n",
    "display([[round(f, 6) for f in history.history['recall'][-10:]]])\n",
    "display([[round(f, 6) for f in history.history['val_recall'][-10:]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_calculus(name, rec, prec):\n",
    "    df_tmp=pd.DataFrame()\n",
    "    df_tmp[name] = 2*np.array(rec)*np.array(prec)/(np.array(rec)+np.array(prec)+tf.keras.backend.epsilon()) # epsilon avoid runtimeWarning: divide by zero encountered in divide...\n",
    "    return df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = f1_calculus(\"f1\", history.history[\"recall\"], history.history[\"precision\"])\n",
    "df_val_tmp = f1_calculus(\"val_f1\", history.history[\"val_recall\"], history.history[\"val_precision\"])\n",
    "\n",
    "plt.plot(df_tmp[\"f1\"], color=\"b\", label=\"Train F1\")\n",
    "plt.plot(df_val_tmp[\"val_f1\"], color=\"r\", label=\"Val F1\")\n",
    "plt.ylabel(\"Values\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.title(\"Bert Base Uncased : F1\")\n",
    "plt.legend()\n",
    "plt.ylim(0,1)\n",
    "save_fig(\"bert_base_uncased_f1\", \"png\")\n",
    "plt.show()\n",
    "\n",
    "display(df_tmp.tail(10))\n",
    "display(df_val_tmp.tail(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "att",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
