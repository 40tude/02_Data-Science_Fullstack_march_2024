{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prelude\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.model_selection    import GridSearchCV, train_test_split\n",
    "from sklearn.metrics            import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.linear_model       import LogisticRegression\n",
    "from sklearn.ensemble           import RandomForestClassifier, GradientBoostingClassifier\n",
    "# from sklearn.svm              import SVC\n",
    "# from sklearn.neighbors        import KNeighborsClassifier\n",
    "\n",
    "from xgboost                    import XGBClassifier \n",
    "from sklearn.pipeline           import Pipeline\n",
    "# from sklearn.impute           import SimpleImputer\n",
    "from sklearn.compose            import ColumnTransformer\n",
    "from sklearn.preprocessing      import OneHotEncoder, StandardScaler, PolynomialFeatures   \n",
    "from sklearn.feature_selection  import SelectKBest, f_classif, chi2\n",
    "\n",
    "# Return pandas DataFrames instead of numpy arrays\n",
    "# from sklearn import set_config\n",
    "# set_config(transform_output=\"pandas\") # ! NOT TESTED YET\n",
    "\n",
    "Gold              = 1.618                          \n",
    "Width             = 12\n",
    "Height            = Width/Gold\n",
    "WidthPx           = 1024\n",
    "HeightPx          = WidthPx/Gold\n",
    "\n",
    "k_result_file       = \"models-benchmark\"\n",
    "k_target            = \"converted\"\n",
    "k_header            = \"conversion_data_test_predictions_\"\n",
    "k_author            = \"PHILIPPE\"\n",
    "k_random_state      = 42            # I know you know ...\n",
    "k_final_test_size   = 20/100        # typic. 20% from the set of the initial observations is set aside for final testing (unseen data)\n",
    "k_test_size         = 20/100        # typic. 20% of the remaining 80% of the initial observation ui used for the test_set (we should say validation_set)\n",
    "k_samples_ratio     = 100/100       # percentage of observations to be taken into account. Pass 100/100 for final testing \n",
    "k_bVerbose          = True          # Enable/disable messages\n",
    "k_bPrePrepocessing  = False         # this flag indicates to do pre-preprocessing or not\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversion Rate Challenge : Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The end result was something like :  \n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"./assets/scores.png\" alt=\"drawing\" width=\"800\"/>\n",
    "<p>\n",
    "\n",
    "Some of the key ideas :\n",
    "1. Being able to compare results from different models on the same dataset\n",
    "1. Being able to test the same model but with different set of parameters\n",
    "1. Act as a host for more sophisticated code\n",
    "    * For example, some functions are in place but commented\n",
    "1. Provide ranges of values for parameters and be able to find the best configuration for a model\n",
    "    * This is supposed to be purely ``declarative`` in order to do many different tests quickly\n",
    "    * No coding requested (if needed, coding can be done in an external file)\n",
    "1. Being able to use, not only a model but a pipe of Transformers, Predictors\n",
    "    * Again, this should be declarative with no coding \n",
    "    * Allow some sort of preprocessing \"per model\"  \n",
    "1. Being able to easily add some preprocessing for all models under test\n",
    "    * Specific code need to be added  but template of code is already in place\n",
    "    * 2 kinds of preprocessing are identified. \n",
    "        * Preprocessing acting on the data red\n",
    "        * Preprocessing acting on X and y dataframes\n",
    "1. Be able to add some features selection for all models under test\n",
    "    * Specific code need to be added but template of code is already in place\n",
    "1. Being able to add some feature engineering for all models under test\n",
    "    * Specific code need to be added but template of code is already in place\n",
    "1. Define train, test and validation sets in order to make sure we can test the best model on \"unseen\" observations\n",
    "1. Save the benchmarks results into csv files\n",
    "1. Save the predictions of the best model in order to send them to the leaderboard\n",
    "1. ...\n",
    "\n",
    "Above, when it is said ``declarative`` here is how it works :\n",
    "* First, the user <span style=\"color:orange\"><b>declares </b></span> a model to test\n",
    "* To do so the user adds a line to the ``models`` list (see below)\n",
    "* Each line, include a ``model_id`` (to identify the model) and ``model_function`` (or pipe of transformers, predictors)\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"./assets/models_naming.png\" alt=\"drawing\" width=\"600\"/>\n",
    "<p>\n",
    "\n",
    "In the picture above, the user declares that LogisticRegression() will be used (it is not commented) with the configuration named LogisticeRegression_0 and LogisticeRegression_1. The third line is simply commented. Commenting is an easy way to discard so model and to speedup benchmarking.\n",
    "\n",
    "* Then the user <span style=\"color:orange\"><b>declares </b></span> the parameters or range of parameters to be used with each models \n",
    "* To do so, the user adds a line to the ``models_params_sets`` dictionary (see below)\n",
    "* Each line consists of a ``model_id`` and a set of named parameters\n",
    "* Parameters can either have a fixed value or a range of values\n",
    "* One model (identified with its model_id) can then be tested with multiple sets of fixed parameters.\n",
    "* A model can also be used with ranges of parameters for which we look for the best set\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"./assets/models_settings.png\" alt=\"drawing\" width=\"800\"/>\n",
    "<p>\n",
    "\n",
    "In the picture above, the user declares that LogisticeRegression_0 will correspond to the base line configuration. Indeed, since the curly braces are empty, every parameter will be defaulted. On the other hand, LogisticeRegression_1 the code will search for the best values of ``C`` and ``penalty``. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-preprocessing\n",
    "\n",
    "* Pre-prepocessing (!= preprocessing) is optional \n",
    "* It is made on the DataFrame before the target (``y``) and the features (``X``) are splitted\n",
    "* It impact all the subsequent operations and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./assets/conversion_data_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function.\n",
    "# print the name of the dataframe passed in a dict\n",
    "\n",
    "def print_dict(dataframes_dict): \n",
    "  \n",
    "  for df_name in dataframes_dict:\n",
    "    df_actual = dataframes_dict.get(df_name)\n",
    "    print(f\"Shape of {df_name} : {df_actual.shape}\")            if k_bVerbose == True else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1 of pre_preprocessing_raw\n",
    "# Remove outliers\n",
    "# One col at a time\n",
    "# Easier to understand\n",
    "\n",
    "# def remove_outliers(df, column):\n",
    "#     Q1 = df[column].quantile(0.25)\n",
    "#     Q3 = df[column].quantile(0.75)\n",
    "#     IQR = Q3 - Q1\n",
    "#     lower_bound = Q1 - 1.5 * IQR\n",
    "#     upper_bound = Q3 + 1.5 * IQR\n",
    "#     df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "#     return df\n",
    "\n",
    "# df = remove_outliers(df, 'age')\n",
    "# df = remove_outliers(df, 'total_pages_visited')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2 of pre_preprocessing_raw\n",
    "# Remove outliers\n",
    "# Mask over both columns\n",
    "# Might be faster\n",
    "\n",
    "# col_of_interrest = df[[\"age\", \"total_pages_visited\"]]\n",
    "\n",
    "# # Q1, Q3, IQR are series\n",
    "# Q1 = col_of_interrest.quantile(0.25)\n",
    "# Q3 = col_of_interrest.quantile(0.75)\n",
    "# IQR = Q3 - Q1\n",
    "\n",
    "# lower_bound = Q1 - 1.5 * IQR\n",
    "# upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# outliers_mask = ((col_of_interrest < lower_bound) | (col_of_interrest > upper_bound)).any(axis=1)\n",
    "# df = df[~outliers_mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=k_target)\n",
    "y = df[k_target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X :\n",
      "   country  age  new_user  source  total_pages_visited\n",
      "0    China   22         1  Direct                    2\n",
      "1       UK   21         1     Ads                    3\n",
      "2  Germany   20         0     Seo                   14\n",
      "3       US   23         1     Seo                    3\n",
      "4       US   28         1  Direct                    3\n",
      "(284580, 5)\n",
      "\n",
      "y :\n",
      "0    0\n",
      "1    0\n",
      "2    1\n",
      "3    0\n",
      "4    0\n",
      "Name: converted, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "if k_bVerbose : \n",
    "  print(\"X :\")\n",
    "  print(X.head())\n",
    "  print(X.shape)\n",
    "  print()\n",
    "\n",
    "  print(\"y :\")\n",
    "  print(y.head())\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Xtrain_back  : (227664, 5)\n",
      "Shape of X_final_test : (56916, 5)\n",
      "Shape of y_train      : (227664,)\n",
      "Shape of y_final_test : (56916,)\n"
     ]
    }
   ],
   "source": [
    "X_train_back, X_final_test, y_train_back, y_final_test = train_test_split(X, y, test_size=k_final_test_size, random_state=k_random_state, stratify = y)\n",
    "\n",
    "dataframes_dict = {'Xtrain_back ': X_train_back, 'X_final_test': X_final_test, 'y_train     ': y_train_back, 'y_final_test': y_final_test}\n",
    "print_dict(dataframes_dict)\n",
    "\n",
    "# Uncomment the lines below to save X and y as .csv for additional testing on colab\n",
    "# df_tmp = pd.concat([y, X], axis=1)\n",
    "# df_tmp.to_csv(\"./assets/4test_colab.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train : (182131, 5)\n",
      "Shape of X_test  : (45533, 5)\n",
      "Shape of y_train : (182131,)\n",
      "Shape of y_test  : (45533,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train_back, y_train_back, test_size=k_test_size, random_state=k_random_state, stratify = y_train_back)\n",
    "\n",
    "dataframes_dict = {'X_train': X_train, 'X_test ': X_test, 'y_train': y_train, 'y_test ': y_test}\n",
    "print_dict(dataframes_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO : see how to transform this code as a pre processing step\n",
    "# TODO : find a way to link as in a receipt differents step in pre processing (what about seleciotb etc.)\n",
    "\n",
    "# This pre-preprocessing differs from the previous one \n",
    "# Indeed, it is defined as a function\n",
    "# It act on two dataframes X and y while the previous one acted on the read values (df) \n",
    "\n",
    "def pre_preprocessing(X, y):\n",
    "  \n",
    "  df_tmp = pd.concat([y, X], axis=1)\n",
    "\n",
    "  # This is an example\n",
    "  df_tmp['weight'] = df_tmp.groupby(df_tmp.columns.tolist(), sort=False).transform('size')\n",
    "  \n",
    "  # This is another example - Remove duplicates\n",
    "  # df_tmp = df_tmp.drop_duplicates()\n",
    "\n",
    "  # Dangerous ? Here I suppose y is always the first col \n",
    "  # See concat above\n",
    "  X = df_tmp.drop(df_tmp.columns[0], axis=1)\n",
    "  y = df_tmp.iloc[:,0]\n",
    "\n",
    "  return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(k_bPrePrepocessing):\n",
    "  print(f\"shape : {X_train.shape}\") if k_bVerbose == True else None\n",
    "  print(f\"shape : {y_train.shape}\") if k_bVerbose == True else None\n",
    "  \n",
    "  X_train, y_train = pre_preprocessing(X_train, y_train)  \n",
    "\n",
    "  print(f\"shape : {X_train.shape}\") if k_bVerbose == True else None\n",
    "  print(f\"shape : {y_train.shape}\") if k_bVerbose == True else None\n",
    "\n",
    "  display(X_train.head(2)) if k_bVerbose == True else None\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(k_bPrePrepocessing):\n",
    "  print(f\"shape : {X_test.shape}\") if k_bVerbose == True else None\n",
    "  print(f\"shape : {y_test.shape}\") if k_bVerbose == True else None\n",
    "  \n",
    "  X_test, y_test = pre_preprocessing(X_test, y_test)  \n",
    "\n",
    "  print(f\"shape : {X_test.shape}\") if k_bVerbose == True else None\n",
    "  print(f\"shape : {y_test.shape}\") if k_bVerbose == True else None\n",
    "\n",
    "  display(X_test.head(2)) if k_bVerbose == True else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'new_user', 'total_pages_visited'], dtype='object')\n",
      "Index(['country', 'source'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# We can either use X_train or X_test to list the names of numerical/categorical columns\n",
    "\n",
    "numeric_features = X_train.select_dtypes(include=\"number\").columns\n",
    "print(numeric_features) if k_bVerbose == True else None\n",
    "\n",
    "categorical_features = X_train.select_dtypes(exclude=\"number\").columns\n",
    "print(categorical_features) if k_bVerbose == True else None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The commented lines might be useful with others dataset\n",
    "\n",
    "numeric_transformer = Pipeline(\n",
    "  steps=[\n",
    "    # (\"imputer_num\", SimpleImputer()),\n",
    "    # (\"imputer_num\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"scaler_num\", StandardScaler()),\n",
    "  ]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "  steps=[\n",
    "    # (\"imputer_cat\", SimpleImputer(fill_value=\"missing\", strategy=\"constant\")),  \n",
    "    # (\"imputer_cat\", SimpleImputer(strategy=\"most_frequent\")),  \n",
    "    # (\"encoder_cat\", OneHotEncoder(handle_unknown='ignore', sparse=False)),                 \n",
    "    (\"encoder_cat\", OneHotEncoder(drop=\"first\")),                 \n",
    "  ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "  transformers=[\n",
    "    (\"num\", numeric_transformer,     numeric_features),\n",
    "    (\"cat\", categorical_transformer, categorical_features),\n",
    "  ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.537  0.676  0.934  0.     0.     1.     0.     0.   ]\n",
      " [-0.791  0.676 -0.562  0.     0.     0.     1.     0.   ]\n",
      " [-0.429  0.676 -1.16   0.     0.     0.     0.     1.   ]\n",
      " [ 0.9    0.676 -1.16   0.     0.     0.     0.     0.   ]\n",
      " [-0.429  0.676 -0.562  0.     0.     0.     0.     1.   ]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num__age</th>\n",
       "      <th>num__new_user</th>\n",
       "      <th>num__total_pages_visited</th>\n",
       "      <th>cat__country_Germany</th>\n",
       "      <th>cat__country_UK</th>\n",
       "      <th>cat__country_US</th>\n",
       "      <th>cat__source_Direct</th>\n",
       "      <th>cat__source_Seo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.537447</td>\n",
       "      <td>0.676139</td>\n",
       "      <td>0.934158</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.790909</td>\n",
       "      <td>0.676139</td>\n",
       "      <td>-0.561734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.428630</td>\n",
       "      <td>0.676139</td>\n",
       "      <td>-1.160091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.899726</td>\n",
       "      <td>0.676139</td>\n",
       "      <td>-1.160091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.428630</td>\n",
       "      <td>0.676139</td>\n",
       "      <td>-0.561734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num__age  num__new_user  num__total_pages_visited  cat__country_Germany  \\\n",
       "0  0.537447       0.676139                  0.934158                   0.0   \n",
       "1 -0.790909       0.676139                 -0.561734                   0.0   \n",
       "2 -0.428630       0.676139                 -1.160091                   0.0   \n",
       "3  0.899726       0.676139                 -1.160091                   0.0   \n",
       "4 -0.428630       0.676139                 -0.561734                   0.0   \n",
       "\n",
       "   cat__country_UK  cat__country_US  cat__source_Direct  cat__source_Seo  \n",
       "0              0.0              1.0                 0.0              0.0  \n",
       "1              0.0              0.0                 1.0              0.0  \n",
       "2              0.0              0.0                 0.0              1.0  \n",
       "3              0.0              0.0                 0.0              0.0  \n",
       "4              0.0              0.0                 0.0              1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)\n",
    "print(X_train[0:5].round(3))    if k_bVerbose == True else None\n",
    "\n",
    "# ! IMPORTANT : because in this script we work with df NOT nd array \n",
    "X_train = pd.DataFrame(X_train, columns=preprocessor.get_feature_names_out())\n",
    "display(X_train.head())         if k_bVerbose == True else None\n",
    "\n",
    "X_test = pd.DataFrame(X_test, columns=preprocessor.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_feature_engineering(data, strategy='None', **kwargs):\n",
    "\n",
    "  \"\"\"\n",
    "  Applies a feature engineering strategy to the data.      \n",
    "\n",
    "  Args: \n",
    "  - data (DataFrame)  : The DataFrame containing the initial data.     \n",
    "  - strategy (str)    : The feature engineering strategy to apply.     \n",
    "  - kwargs            : Parameters specific to the feature engineering strategy.      \n",
    "\n",
    "  Returns (DataFrame) : The DataFrame containing the transformed data.     \n",
    "  \"\"\"\n",
    "\n",
    "  match strategy:\n",
    "\n",
    "    case 'None':\n",
    "      transformed_df = data.copy()\n",
    "     \n",
    "    case 'polynomial_features':\n",
    "      degree = kwargs.get('degree', 2)          # 2 by default\n",
    "      poly = PolynomialFeatures(degree=degree)\n",
    "      transformed_data = poly.fit_transform(data)\n",
    "\n",
    "      original_feature_names = data.columns\n",
    "      feature_combinations = poly.powers_\n",
    "\n",
    "      # Generate names for the new features\n",
    "      feature_names = [\"\"]\n",
    "      for feature_combination in feature_combinations[1:]:\n",
    "          new_feature_name = \"*\".join([f\"{orig_feature}^{power}\" if power > 1 else orig_feature for orig_feature, power in zip(original_feature_names, feature_combination)])\n",
    "          feature_names.append(new_feature_name)\n",
    "\n",
    "      # new df - transformed features and their names\n",
    "      transformed_df = pd.DataFrame(transformed_data, columns=feature_names)\n",
    "\n",
    "    case 'log_transform':\n",
    "      features_to_transform = kwargs.get('features_to_transform', [])\n",
    "      transformed_df = data.copy()\n",
    "      transformed_df[features_to_transform] = np.log(data[features_to_transform] + 1) # log neperien\n",
    "\n",
    "    case 'custom_feature_engineering':\n",
    "      # Design your own pizza here\n",
    "      # One can use kwargs\n",
    "      transformed_df = data.copy()\n",
    "\n",
    "    case _:\n",
    "      raise ValueError(\"Feature engineering strategy not recognized.\")\n",
    "\n",
    "  return transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_feature_selection(X_train, y_train, X_test, feature_selection_id='None', **kwargs):\n",
    "\n",
    "  \"\"\"\n",
    "  Applies a feature selection strategy to the data.      \n",
    "\n",
    "  Args: \n",
    "  - X_train, y_train, X_test (DataFrame)  : the dataframe\n",
    "  - feature_selection_method (str)        : default None. The delection to be applied     \n",
    "  - kwargs                                : Parameters specific to the feature selection strategy      \n",
    "\n",
    "  Returns (DataFrame)                     : The DataFrame containing the selected features     \n",
    "  \"\"\"\n",
    "\n",
    "  match feature_selection_id:\n",
    "      case \"None\":\n",
    "        X_train_selected_df = X_train\n",
    "        X_test_selected_df = X_test\n",
    "               \n",
    "      case 'SelectKBest':\n",
    "        k = kwargs.get('k', 10)                            # 10 by default\n",
    "        if df.shape[1]<k:\n",
    "          k = df.shape[1]\n",
    "        selector = SelectKBest(score_func=f_classif, k=k)\n",
    "        X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "        X_test_selected = selector.transform(X_test)\n",
    "\n",
    "        X_train_selected_df = pd.DataFrame(X_train_selected, columns=X_train.columns[selector.get_support()])\n",
    "        X_test_selected_df = pd.DataFrame(X_test_selected, columns=X_train.columns[selector.get_support()])\n",
    "\n",
    "      case 'chi2':\n",
    "        selector = SelectKBest(score_func=chi2)\n",
    "        X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "        X_test_selected = selector.transform(X_test)\n",
    "\n",
    "        X_train_selected_df = pd.DataFrame(X_train_selected, columns=X_train.columns[selector.get_support()])\n",
    "        X_test_selected_df = pd.DataFrame(X_test_selected, columns=X_train.columns[selector.get_support()])\n",
    "\n",
    "      case 'Baseline':\n",
    "        features_list = kwargs.get('features_list', [])\n",
    "        X_train_selected_df = X_train.loc[:, features_list]\n",
    "        X_test_selected_df = X_test.loc[:, features_list]\n",
    "\n",
    "      case 'Baseline2':\n",
    "        features_list = kwargs.get('features_list', [])\n",
    "        X_train_selected_df = X_train.loc[:, features_list]\n",
    "        X_test_selected_df = X_test.loc[:, features_list]\n",
    "\n",
    "      case 'custom_feature_selection':\n",
    "        # Design your own pizza here\n",
    "        # One can use kwargs\n",
    "        X_train_selected_df = X_train\n",
    "        X_test_selected_df = X_test\n",
    "      \n",
    "      case _:\n",
    "        raise ValueError(\"Feature selection method not recognized.\")\n",
    "\n",
    "  return X_train_selected_df, X_test_selected_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_scores(model, params, X_train, y_train, X_test, y_test):\n",
    "\n",
    "  grid_search = GridSearchCV(model, param_grid=params, cv=5, scoring='f1', n_jobs=-1)\n",
    "  grid_search.fit(X_train, y_train)\n",
    "\n",
    "  best_params = grid_search.best_params_\n",
    "  print(best_params)                        if k_bVerbose == True else None\n",
    "\n",
    "  # ! don't do that. Bad idea\n",
    "  # best_estimator = gridsearch.best_estimator_\n",
    "  # Do this instead\n",
    "  model.set_params(**best_params)\n",
    "  # https://stackoverflow.com/questions/69326639/sklearn-warning-valid-feature-names-in-version-1-0\n",
    "  model.fit(X_train.values, y_train)\n",
    "  y_pred = model.predict(X_test.values)\n",
    "\n",
    "  scores = {\n",
    "    'accuracy'  : accuracy_score  (y_test, y_pred),\n",
    "    'precision' : precision_score (y_test, y_pred),\n",
    "    'recall'    : recall_score    (y_test, y_pred),\n",
    "    'f1'        : f1_score        (y_test, y_pred)\n",
    "  }\n",
    "\n",
    "  print(f1_score(y_test, y_pred))           if k_bVerbose == True else None\n",
    "\n",
    "  return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dataframe to store the results\n",
    "results_df = pd.DataFrame(columns=[\"Pre_processing\", 'Feature_Engineering', 'Feature_Selection', 'Model', 'Accuracy', 'Precision', 'Recall', 'F1'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Engineering Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategies for feature engineering\n",
    "# At least one strategy MUST be active\n",
    "\n",
    "# fes stands for features engineering strategies\n",
    "\n",
    "# One fes = fes id + fes function\n",
    "# You can define as many selection id as you like\n",
    "# Make sure to define a set of parameters (even if there is no parameters) for each selection id\n",
    "feature_engineering_strategies = [\n",
    "  ('None'           , \"None\"),\n",
    "  # (\"Poly Feat\"      , \"polynomial_features\"),       # degree\n",
    "  # (\"Log Transform\"  , \"log_transform\"),             # features_to_transform\n",
    "]\n",
    "\n",
    "# Define paramter for each strategy\n",
    "# You can let them uncommented\n",
    "engineering_params_sets = {\n",
    "  'None'            : {},\n",
    "  'Poly Feat'       : {'degree':1},                         \n",
    "  'Log Transform'   : {'features_to_transform': [0, 1, 2]}, # ! NOT TESTED!!!!!!!!!!!!!! \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Selection Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO : simply. Indeed, only tje selection_id is needed\n",
    "# Strategies for feature selection\n",
    "# At least one strategy id MUST be active\n",
    "# You can define as many selection id as you like\n",
    "# Make sure to define a set of parameters (even if there is no parameter) for each selection id\n",
    "feature_selection_strategies = [\n",
    "  ('None'),\n",
    "  #('Baseline'),\n",
    "  #('Baseline2'),\n",
    "  # ('SelectKBest_2'), \n",
    "  # (\"SelectKBest_1\") , \n",
    "  # ('chi2'),                            # !!! PAS TESTE\n",
    "]\n",
    "\n",
    "# Define paraameters for each strategy\n",
    "# You can let them uncommented\n",
    "selection_params_sets = {\n",
    "  'None'          : {},\n",
    "  'Baseline'      : {'features_list' : ['num__total_pages_visited'] }, # pay attention to the num__ (double underscore)\n",
    "  'Baseline2'     : {'features_list' : ['num__total_pages_visited', 'num__age'] }, \n",
    "  'SelectKBest_1' : {'k':1},                         \n",
    "  'SelectKBest_2' : {'k':2},                         \n",
    "  'chi2'          : {}, \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models & Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A model = a model_id and a model_function\n",
    "# You can define as many model_id as you like\n",
    "# Make sure to define a set of parameters (even if there is no parameters) for each model id\n",
    "\n",
    "pipe_4 = Pipeline(steps=[\n",
    "    (\"poly\", PolynomialFeatures()),\n",
    "    (\"logit\", LogisticRegression())\n",
    "])\n",
    "\n",
    "models = [\n",
    "    (\"LogisticRegression_0\", LogisticRegression()),\n",
    "    # (\"LogisticRegression_1\", LogisticRegression()),\n",
    "    #(\"LogisticRegression_2\", LogisticRegression()),\n",
    "    # (\"LogisticRegression_3\", LogisticRegression()),\n",
    "    (\"LogisticRegression_4\", pipe_4),\n",
    "    \n",
    "    (\"RandomForestClassifier_0\", RandomForestClassifier()),\n",
    "    # ('Random Forest', RandomForestClassifier()),\n",
    "    \n",
    "    # ('XGBoost', XGBClassifier()),\n",
    "    # (\"Gradient Boost Clf\", GradientBoostingClassifier())\n",
    "    # ('SVM', SVC()),\n",
    "    # ('KNN', KNeighborsClassifier()),\n",
    "]\n",
    "\n",
    "# Set of hyperparameters for each model_id\n",
    "models_params_sets = {\n",
    "    'LogisticRegression_0'      : {},          # baseline model\n",
    "    'LogisticRegression_1'      : {'C': [0.1, 1, 10], 'penalty': ['l2']},\n",
    "    'LogisticRegression_2'      : {'C': [100], 'max_iter': [1000], 'random_state': [k_random_state]},\n",
    "    'LogisticRegression_3'      : {'penalty' : ['l2', 'None'], 'C': [0.01, 0.1, 1, 10], 'class_weight' : ['None', 'dic', 'balanced'], 'solver' : ['lbfgs', 'newton-cg', 'newton-cholesky', 'sag', 'saga'], 'random_state': [k_random_state]},\n",
    "    'LogisticRegression_4'      : {\"poly__degree\" : [1], \"logit__C\" : [3, 0.1], \"logit__penalty\" : [\"none\", \"l2\"], },\n",
    "    'LogisticRegression_99'     : {'C' : [0.75 + i * 0.05 for i in range(20)], 'solver' : ['lbfgs', \"saga\", \"newton-cholesky\", 'newton-cg', 'sag']},       # 'random_state': [k_random_state]},\n",
    "    'RandomForestClassifier_0'  : {\"n_estimators\" : [200], \"max_depth\":[20], \"min_samples_split\":[20], \"min_samples_leaf\":[4], \"max_features\":[\"sqrt\"], \"random_state\":[42]},\n",
    "    # https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression\n",
    "    'Random Forest'             : {'n_estimators': [100, 200, 300], 'max_depth': [None, 10, 20]},\n",
    "    'SVM'                       : {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']},\n",
    "    'KNN'                       : {'n_neighbors': [3, 5, 7], 'weights': ['uniform', 'distance']},\n",
    "    'XGBoost'                   : {'booster':['gbtree']},\n",
    "    # https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/\n",
    "    \"Gradient Boost Clf\"        : {'learning_rate' : [0.1, 0.01], 'n_estimators': [100, 200], 'subsample' : [1.0, 0.8]},\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num__age</th>\n",
       "      <th>num__new_user</th>\n",
       "      <th>num__total_pages_visited</th>\n",
       "      <th>cat__country_Germany</th>\n",
       "      <th>cat__country_UK</th>\n",
       "      <th>cat__country_US</th>\n",
       "      <th>cat__source_Direct</th>\n",
       "      <th>cat__source_Seo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.537447</td>\n",
       "      <td>0.676139</td>\n",
       "      <td>0.934158</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.790909</td>\n",
       "      <td>0.676139</td>\n",
       "      <td>-0.561734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.428630</td>\n",
       "      <td>0.676139</td>\n",
       "      <td>-1.160091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.899726</td>\n",
       "      <td>0.676139</td>\n",
       "      <td>-1.160091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.428630</td>\n",
       "      <td>0.676139</td>\n",
       "      <td>-0.561734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num__age  num__new_user  num__total_pages_visited  cat__country_Germany  \\\n",
       "0  0.537447       0.676139                  0.934158                   0.0   \n",
       "1 -0.790909       0.676139                 -0.561734                   0.0   \n",
       "2 -0.428630       0.676139                 -1.160091                   0.0   \n",
       "3  0.899726       0.676139                 -1.160091                   0.0   \n",
       "4 -0.428630       0.676139                 -0.561734                   0.0   \n",
       "\n",
       "   cat__country_UK  cat__country_US  cat__source_Direct  cat__source_Seo  \n",
       "0              0.0              1.0                 0.0              0.0  \n",
       "1              0.0              0.0                 1.0              0.0  \n",
       "2              0.0              0.0                 0.0              1.0  \n",
       "3              0.0              0.0                 0.0              0.0  \n",
       "4              0.0              0.0                 0.0              1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train            :  <class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num__age</th>\n",
       "      <th>num__new_user</th>\n",
       "      <th>num__total_pages_visited</th>\n",
       "      <th>cat__country_Germany</th>\n",
       "      <th>cat__country_UK</th>\n",
       "      <th>cat__country_US</th>\n",
       "      <th>cat__source_Direct</th>\n",
       "      <th>cat__source_Seo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.537447</td>\n",
       "      <td>0.676139</td>\n",
       "      <td>0.934158</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.790909</td>\n",
       "      <td>0.676139</td>\n",
       "      <td>-0.561734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.428630</td>\n",
       "      <td>0.676139</td>\n",
       "      <td>-1.160091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.899726</td>\n",
       "      <td>0.676139</td>\n",
       "      <td>-1.160091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.428630</td>\n",
       "      <td>0.676139</td>\n",
       "      <td>-0.561734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num__age  num__new_user  num__total_pages_visited  cat__country_Germany  \\\n",
       "0  0.537447       0.676139                  0.934158                   0.0   \n",
       "1 -0.790909       0.676139                 -0.561734                   0.0   \n",
       "2 -0.428630       0.676139                 -1.160091                   0.0   \n",
       "3  0.899726       0.676139                 -1.160091                   0.0   \n",
       "4 -0.428630       0.676139                 -0.561734                   0.0   \n",
       "\n",
       "   cat__country_UK  cat__country_US  cat__source_Direct  cat__source_Seo  \n",
       "0              0.0              1.0                 0.0              0.0  \n",
       "1              0.0              0.0                 1.0              0.0  \n",
       "2              0.0              0.0                 0.0              1.0  \n",
       "3              0.0              0.0                 0.0              0.0  \n",
       "4              0.0              0.0                 0.0              1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_engineered :  <class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num__age</th>\n",
       "      <th>num__new_user</th>\n",
       "      <th>num__total_pages_visited</th>\n",
       "      <th>cat__country_Germany</th>\n",
       "      <th>cat__country_UK</th>\n",
       "      <th>cat__country_US</th>\n",
       "      <th>cat__source_Direct</th>\n",
       "      <th>cat__source_Seo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.537447</td>\n",
       "      <td>0.676139</td>\n",
       "      <td>0.934158</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.790909</td>\n",
       "      <td>0.676139</td>\n",
       "      <td>-0.561734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.428630</td>\n",
       "      <td>0.676139</td>\n",
       "      <td>-1.160091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.899726</td>\n",
       "      <td>0.676139</td>\n",
       "      <td>-1.160091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.428630</td>\n",
       "      <td>0.676139</td>\n",
       "      <td>-0.561734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num__age  num__new_user  num__total_pages_visited  cat__country_Germany  \\\n",
       "0  0.537447       0.676139                  0.934158                   0.0   \n",
       "1 -0.790909       0.676139                 -0.561734                   0.0   \n",
       "2 -0.428630       0.676139                 -1.160091                   0.0   \n",
       "3  0.899726       0.676139                 -1.160091                   0.0   \n",
       "4 -0.428630       0.676139                 -0.561734                   0.0   \n",
       "\n",
       "   cat__country_UK  cat__country_US  cat__source_Direct  cat__source_Seo  \n",
       "0              0.0              1.0                 0.0              0.0  \n",
       "1              0.0              0.0                 1.0              0.0  \n",
       "2              0.0              0.0                 0.0              1.0  \n",
       "3              0.0              0.0                 0.0              0.0  \n",
       "4              0.0              0.0                 0.0              1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_selected   :  <class 'pandas.core.frame.DataFrame'>\n",
      "None-None-LogisticRegression_0 : \n",
      "{}\n",
      "0.7407129455909943\n",
      "None-None-LogisticRegression_4 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\phili\\anaconda3\\envs\\jedha\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\phili\\anaconda3\\envs\\jedha\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logit__C': 3, 'logit__penalty': 'none', 'poly__degree': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\phili\\anaconda3\\envs\\jedha\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\phili\\anaconda3\\envs\\jedha\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7404351087771943\n",
      "None-None-RandomForestClassifier_0 : \n",
      "{'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 20, 'n_estimators': 200, 'random_state': 42}\n",
      "0.7342995169082126\n",
      "Scores on test set, ordered by F1 descending : \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pre_processing</th>\n",
       "      <th>Feature_Engineering</th>\n",
       "      <th>Feature_Selection</th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LogisticRegression_0</td>\n",
       "      <td>0.984824</td>\n",
       "      <td>0.825251</td>\n",
       "      <td>0.671886</td>\n",
       "      <td>0.740713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LogisticRegression_4</td>\n",
       "      <td>0.984802</td>\n",
       "      <td>0.824561</td>\n",
       "      <td>0.671886</td>\n",
       "      <td>0.740435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>RandomForestClassifier_0</td>\n",
       "      <td>0.984297</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.672566</td>\n",
       "      <td>0.734300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pre_processing Feature_Engineering Feature_Selection  \\\n",
       "0           False                None              None   \n",
       "1           False                None              None   \n",
       "2           False                None              None   \n",
       "\n",
       "                      Model  Accuracy  Precision    Recall        F1  \n",
       "0      LogisticRegression_0  0.984824   0.825251  0.671886  0.740713  \n",
       "1      LogisticRegression_4  0.984802   0.824561  0.671886  0.740435  \n",
       "2  RandomForestClassifier_0  0.984297   0.808511  0.672566  0.734300  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_lst=[]\n",
    "\n",
    "# fes = Feature Engineering Strategy\n",
    "for fes_id, fes_fn in feature_engineering_strategies:\n",
    "  \n",
    "  display(X_train.head(5))                        if k_bVerbose == True else None\n",
    "  print(\"X_train            : \", type(X_train))   if k_bVerbose == True else None\n",
    "\n",
    "  # Loop over feature engineering\n",
    "  X_train_engineered = apply_feature_engineering(X_train, fes_fn, **engineering_params_sets[fes_id])\n",
    "  X_test_engineered  = apply_feature_engineering(X_test,  fes_fn, **engineering_params_sets[fes_id])\n",
    "  # DataFrame\n",
    "  display(X_train_engineered.head(5))                       if k_bVerbose == True else None\n",
    "  print(\"X_train_engineered : \", type(X_train_engineered))  if k_bVerbose == True else None\n",
    "\n",
    "  # Loop over features selection\n",
    "  for selection_id in feature_selection_strategies:\n",
    "    X_train_selected, X_test_selected = apply_feature_selection(X_train_engineered, y_train, X_test_engineered, selection_id, **selection_params_sets[selection_id])\n",
    "    # DataFrame\n",
    "    display(X_train_selected.head(5))                       if k_bVerbose == True else None\n",
    "    print(\"X_train_selected   : \", type(X_train_selected))  if k_bVerbose == True else None\n",
    "    \n",
    "    # Loop over models\n",
    "    for model_id, model_fn in models:\n",
    "      print(f\"{fes_id}-{selection_id}-{model_id} : \")\n",
    "      scores = evaluate_model_scores(model_fn, models_params_sets[model_id], X_train_selected, y_train, X_test_selected, y_test)\n",
    "      \n",
    "      results_lst.append(\n",
    "        {\n",
    "          'Pre_processing'      : k_bPrePrepocessing,\n",
    "          'Feature_Engineering' : fes_id,\n",
    "          'Feature_Selection'   : selection_id,\n",
    "          'Model'               : model_id,\n",
    "          'Accuracy'            : scores['accuracy'],\n",
    "          'Precision'           : scores['precision'],\n",
    "          'Recall'              : scores['recall'],\n",
    "          'F1'                  : scores['f1']\n",
    "        }\n",
    "      )\n",
    "\n",
    "results_df = pd.concat([pd.DataFrame([result]) for result in results_lst], ignore_index=True)\n",
    "print(\"Scores on test set, ordered by F1 descending : \")\n",
    "display(results_df.sort_values(by=\"F1\", ascending=False))\n",
    "\n",
    "# Save the results of the benchmark in a csv file\n",
    "trailer = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "out_file = \"./assets/\" + k_result_file + \"-\" + trailer + \".csv\"\n",
    "results_df.to_csv(out_file, encoding=\"utf8\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\"><b>RESULTS : Benchmarks on test set </b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on the whole dataset \n",
    "* DOES NOT INCLUDE X_final_test nor y_final_test \n",
    "* No division between train and test set\n",
    "* The idea is to leverage the maximum of observations to adjust model's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X : (227664, 5)\n",
      "Shape of y : (227664,)\n"
     ]
    }
   ],
   "source": [
    "# Copy X_train_back and y_train_back\n",
    "# to act as if we were working on the whole dataset\n",
    "\n",
    "X = X_train_back.copy()\n",
    "y = y_train_back.copy()\n",
    "\n",
    "print(f\"Shape of X : {X.shape}\") if k_bVerbose == True else None\n",
    "print(f\"Shape of y : {y.shape}\") if k_bVerbose == True else None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(k_bPrePrepocessing):\n",
    "  print(f\"shape : {X.shape}\") if k_bVerbose == True else None\n",
    "  print(f\"shape : {y.shape}\") if k_bVerbose == True else None\n",
    "  \n",
    "  X, y = pre_preprocessing(X, y)  \n",
    "\n",
    "  print(f\"shape : {X.shape}\") if k_bVerbose == True else None\n",
    "  print(f\"shape : {y.shape}\") if k_bVerbose == True else None\n",
    "\n",
    "  display(X.head(2)) if k_bVerbose == True else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.277  0.676 -0.262  0.     0.     1.     0.     0.   ]\n",
      " [-0.189  0.676 -0.561  0.     0.     0.     0.     0.   ]\n",
      " [ 0.657 -1.479 -0.561  0.     0.     1.     0.     1.   ]\n",
      " [-0.914  0.676  0.934  0.     0.     1.     0.     1.   ]\n",
      " [ 1.262  0.676 -0.561  0.     1.     0.     0.     0.   ]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num__age</th>\n",
       "      <th>num__new_user</th>\n",
       "      <th>num__total_pages_visited</th>\n",
       "      <th>cat__country_Germany</th>\n",
       "      <th>cat__country_UK</th>\n",
       "      <th>cat__country_US</th>\n",
       "      <th>cat__source_Direct</th>\n",
       "      <th>cat__source_Seo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.537447</td>\n",
       "      <td>0.676139</td>\n",
       "      <td>0.934158</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.790909</td>\n",
       "      <td>0.676139</td>\n",
       "      <td>-0.561734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.428630</td>\n",
       "      <td>0.676139</td>\n",
       "      <td>-1.160091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.899726</td>\n",
       "      <td>0.676139</td>\n",
       "      <td>-1.160091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.428630</td>\n",
       "      <td>0.676139</td>\n",
       "      <td>-0.561734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num__age  num__new_user  num__total_pages_visited  cat__country_Germany  \\\n",
       "0  0.537447       0.676139                  0.934158                   0.0   \n",
       "1 -0.790909       0.676139                 -0.561734                   0.0   \n",
       "2 -0.428630       0.676139                 -1.160091                   0.0   \n",
       "3  0.899726       0.676139                 -1.160091                   0.0   \n",
       "4 -0.428630       0.676139                 -0.561734                   0.0   \n",
       "\n",
       "   cat__country_UK  cat__country_US  cat__source_Direct  cat__source_Seo  \n",
       "0              0.0              1.0                 0.0              0.0  \n",
       "1              0.0              0.0                 1.0              0.0  \n",
       "2              0.0              0.0                 0.0              1.0  \n",
       "3              0.0              0.0                 0.0              0.0  \n",
       "4              0.0              0.0                 0.0              1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(227664, 8)\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "X = preprocessor.fit_transform(X)\n",
    "print(X[0:5].round(3))  if k_bVerbose == True else None\n",
    "\n",
    "# ! IMPORTANT because is this code we \"play\" with df NOT nd arrays\n",
    "X = pd.DataFrame(X, columns=preprocessor.get_feature_names_out())\n",
    "display(X_train.head()) if k_bVerbose == True else None\n",
    "\n",
    "print(X.shape)          if k_bVerbose == True else None\n",
    "print(type(X))          if k_bVerbose == True else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "{}\n",
      "[0 0 0 ... 0 0 0]\n",
      "f1 \t\t precision \t recall\n",
      "0.762056 \t 0.854749 \t 0.687500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\phili\\anaconda3\\envs\\jedha\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the settings of the best classifier\n",
    "# fes       = feature engineering strategy\n",
    "# fs        = feature selection\n",
    "# model_id  = model id\n",
    "\n",
    "id  = results_df['F1'].idxmax()\n",
    "\n",
    "fes_id = results_df.at[id, \"Feature_Engineering\"]\n",
    "for fes_current_id, fes_current_fn in feature_engineering_strategies:\n",
    "    if  fes_id == fes_current_id:\n",
    "        fes_fn = fes_current_fn\n",
    "        break\n",
    "\n",
    "fs_id  = results_df.at[id, \"Feature_Selection\"]\n",
    "# for fs_current_id in feature_selection_strategies:\n",
    "#     if  fs_id == fs_current_id:\n",
    "#         fs_fn = fs_current_fn\n",
    "#         break\n",
    "\n",
    "model_id = results_df.at[id, \"Model\"]\n",
    "for model_current_id, model_current_fn in models:\n",
    "    if  model_id == model_current_id:\n",
    "        model_fn = model_current_fn\n",
    "        break\n",
    "\n",
    "# Now it got the settings\n",
    "# It goes through the whole process again applying setting on the whole dataset\n",
    "X_engineered  = apply_feature_engineering(X, fes_fn, **engineering_params_sets[fes_id])\n",
    "print(type(X_engineered))   if k_bVerbose == True else None\n",
    "\n",
    "X_selected, _ = apply_feature_selection(X_engineered, y, X_engineered, fs_id, **selection_params_sets[fs_id])\n",
    "print(type(X_selected))     if k_bVerbose == True else None\n",
    "\n",
    "# We call explictily GridSearchCV from here because we need to access to best_params_ \n",
    "grid_search = GridSearchCV(model_fn, models_params_sets[model_id], cv=5, scoring='f1', n_jobs=-1)\n",
    "grid_search.fit(X_selected, y)\n",
    "\n",
    "\n",
    "# TODO make a test. We should be able to remove those lines\n",
    "# TODO I suspect the model keep the best params\n",
    "best_params = grid_search.best_params_\n",
    "print(best_params)                        if k_bVerbose == True else None\n",
    "\n",
    "# model_fn.set_params(**best_params)\n",
    "# print(X_selected.columns)   if k_verbose == True else None\n",
    "# model_fn.fit(X_selected, y) \n",
    "best_estimator = grid_search.best_estimator_\n",
    "y_pred = best_estimator.predict(X.values)\n",
    "print(y_pred)                 if k_bVerbose == True else None\n",
    "\n",
    "print(f\"f1 \\t\\t precision \\t recall\")\n",
    "print(f\"{f1_score(y,  y_pred):.6f} \\t {precision_score(y,  y_pred):.6f} \\t {recall_score(y,  y_pred):.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\"><b>RESULTS : Best model on whole dataset</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions on the unseen dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(k_bPrePrepocessing):\n",
    "  print(f\"shape : {X_final_test.shape}\") if k_bVerbose == True else None\n",
    "  print(f\"shape : {y_final_test.shape}\") if k_bVerbose == True else None\n",
    "  \n",
    "  X_final_test, y_final_test = pre_preprocessing(X_final_test, y_final_test)  \n",
    "\n",
    "  print(f\"shape : {X_final_test.shape}\") if k_bVerbose == True else None\n",
    "  print(f\"shape : {y_final_test.shape}\") if k_bVerbose == True else None\n",
    "\n",
    "  display(X_final_test.head(2)) if k_bVerbose == True else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.174  0.676 -0.262  0.     0.     1.     0.     1.   ]\n",
      " [-0.068  0.676  0.037  0.     1.     0.     0.     1.   ]\n",
      " [ 0.053  0.676  0.037  0.     0.     0.     0.     1.   ]\n",
      " [ 2.47  -1.479  0.037  0.     0.     1.     0.     1.   ]\n",
      " [-1.277  0.676 -0.561  0.     0.     1.     1.     0.   ]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num__age</th>\n",
       "      <th>num__new_user</th>\n",
       "      <th>num__total_pages_visited</th>\n",
       "      <th>cat__country_Germany</th>\n",
       "      <th>cat__country_UK</th>\n",
       "      <th>cat__country_US</th>\n",
       "      <th>cat__source_Direct</th>\n",
       "      <th>cat__source_Seo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.173941</td>\n",
       "      <td>0.676130</td>\n",
       "      <td>-0.261847</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.067800</td>\n",
       "      <td>0.676130</td>\n",
       "      <td>0.037215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.053070</td>\n",
       "      <td>0.676130</td>\n",
       "      <td>0.037215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.470480</td>\n",
       "      <td>-1.479005</td>\n",
       "      <td>0.037215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.276505</td>\n",
       "      <td>0.676130</td>\n",
       "      <td>-0.560909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num__age  num__new_user  num__total_pages_visited  cat__country_Germany  \\\n",
       "0  0.173941       0.676130                 -0.261847                   0.0   \n",
       "1 -0.067800       0.676130                  0.037215                   0.0   \n",
       "2  0.053070       0.676130                  0.037215                   0.0   \n",
       "3  2.470480      -1.479005                  0.037215                   0.0   \n",
       "4 -1.276505       0.676130                 -0.560909                   0.0   \n",
       "\n",
       "   cat__country_UK  cat__country_US  cat__source_Direct  cat__source_Seo  \n",
       "0              0.0              1.0                 0.0              1.0  \n",
       "1              1.0              0.0                 0.0              1.0  \n",
       "2              0.0              0.0                 0.0              1.0  \n",
       "3              0.0              1.0                 0.0              1.0  \n",
       "4              0.0              1.0                 1.0              0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56916, 8)\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# X_final_test = preprocessor.fit_transform(X_final_test)\n",
    "X_final_test = preprocessor.transform(X_final_test)\n",
    "print(X_final_test[0:5].round(3))  if k_bVerbose == True else None\n",
    "\n",
    "# ! IMPORTANT because is this code we \"play\" with df NOT nd arrays\n",
    "X_final_test = pd.DataFrame(X_final_test, columns=preprocessor.get_feature_names_out())\n",
    "display(X_final_test.head())       if k_bVerbose == True else None\n",
    "\n",
    "print(X_final_test.shape)          if k_bVerbose == True else None\n",
    "print(type(X_final_test))          if k_bVerbose == True else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "f1 \t\t precision \t recall\n",
      "0.768252 \t 0.865529 \t 0.690632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\phili\\anaconda3\\envs\\jedha\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_final_pred = best_estimator.predict(X_final_test.values)\n",
    "print(y_final_pred)                 if k_bVerbose == True else None\n",
    "\n",
    "\n",
    "print(f\"f1 \\t\\t precision \\t recall\")\n",
    "print(f\"{f1_score(y_final_test,  y_final_pred):.6f} \\t {precision_score(y_final_test,  y_final_pred):.6f} \\t {recall_score(y_final_test,  y_final_pred):.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\"><b>RESULTS : Best model on Unknown Data</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions on the dataset without label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(31620, 5)\n"
     ]
    }
   ],
   "source": [
    "df_no_labels = pd.read_csv('./assets/conversion_data_test.csv')\n",
    "print(type(df_no_labels))   if k_bVerbose == True else None\n",
    "print(df_no_labels.shape)   if k_bVerbose == True else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>age</th>\n",
       "      <th>new_user</th>\n",
       "      <th>source</th>\n",
       "      <th>total_pages_visited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UK</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>Seo</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UK</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>Direct</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country  age  new_user  source  total_pages_visited\n",
       "0      UK   28         0     Seo                   16\n",
       "1      UK   22         1  Direct                    5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_no_labels = df_no_labels.copy()\n",
    "\n",
    "if(k_bPrePrepocessing):\n",
    "  print(f\"shape : {df_no_labels.shape}\")          if k_bVerbose == True else None\n",
    "  # X_no_labels = pre_preprocessing(df_no_labels) \n",
    "  X_no_labels['weight'] = X_no_labels.groupby(X_no_labels.columns.tolist(), sort=False).transform('size')\n",
    "  print(f\"shape : {X_no_labels.shape}\")           if k_bVerbose == True else None\n",
    "  \n",
    "\n",
    "print(type(X_no_labels))                          if k_bVerbose == True else None\n",
    "display(X_no_labels.head(2))                      if k_bVerbose == True else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31620, 8)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(31620, 8)\n"
     ]
    }
   ],
   "source": [
    "X_no_labels = preprocessor.transform(X_no_labels)\n",
    "print(X_no_labels.shape)            if k_bVerbose == True else None\n",
    "\n",
    "# ! IMPORTANT : because in this script we work with df NOT nd array \n",
    "X_no_labels = pd.DataFrame(X_no_labels, columns=preprocessor.get_feature_names_out())\n",
    "\n",
    "print(type(X_no_labels))            if k_bVerbose == True else None\n",
    "print(X_no_labels.shape)            if k_bVerbose == True else None\n",
    "# print(X_no_labels[0:5,:].round(3))  if k_verbose == True else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['num__age', 'num__new_user', 'num__total_pages_visited',\n",
      "       'cat__country_Germany', 'cat__country_UK', 'cat__country_US',\n",
      "       'cat__source_Direct', 'cat__source_Seo'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\phili\\anaconda3\\envs\\jedha\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 1, 0], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31620,)\n"
     ]
    }
   ],
   "source": [
    "print(X_no_labels.columns)   if k_bVerbose == True else None\n",
    "y_no_labels = best_estimator.predict(X_no_labels.values)\n",
    "\n",
    "display(y_no_labels)                if k_bVerbose == True else None\n",
    "print(y_no_labels.shape)            if k_bVerbose == True else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\phili\\anaconda3\\envs\\jedha\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "  'converted' : best_estimator.predict(X_no_labels.values)\n",
    "}\n",
    "\n",
    "y_predictions = pd.DataFrame(columns=['converted'], data = data)\n",
    "\n",
    "trailer         = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "out_file = \"./assets/\" + k_header + k_author + \"-\" + trailer + \".csv\"\n",
    "y_predictions.to_csv(out_file, index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jedha",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
